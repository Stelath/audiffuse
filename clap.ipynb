{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import laion_clap\n",
    "from laion_clap.training.data import get_audio_features\n",
    "from es_dataset import EpidemicSoundDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantization\n",
    "def int16_to_float32(x):\n",
    "    return (x / 32767.0).astype(np.float32)\n",
    "\n",
    "\n",
    "def float32_to_int16(x):\n",
    "    x = np.clip(x, a_min=-1., a_max=1.)\n",
    "    return (x * 32767.).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = laion_clap.CLAP_Module(enable_fusion=True)\n",
    "model.load_ckpt() # download the default pretrained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/korte/micromamba/envs/ml/lib/python3.9/site-packages/torchaudio/transforms/_transforms.py:611: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
      "  warnings.warn(\n",
      "/home/korte/micromamba/envs/ml/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_waveform = int16_to_float32(float32_to_int16(audio_data))\n",
    "audio_waveform = torch.from_numpy(audio_waveform).float()\n",
    "\n",
    "temp_dict = {}\n",
    "temp_dict = get_audio_features(\n",
    "    temp_dict, audio_waveform, 480000, \n",
    "    data_truncating='fusion', \n",
    "    data_filling='repeatpad',\n",
    "    audio_cfg=model.model_cfg['audio_cfg'],\n",
    "    require_grad=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict['mel_fusion'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_length': 1024,\n",
       " 'clip_samples': 480000,\n",
       " 'mel_bins': 64,\n",
       " 'sample_rate': 48000,\n",
       " 'window_size': 1024,\n",
       " 'hop_size': 480,\n",
       " 'fmin': 50,\n",
       " 'fmax': 14000,\n",
       " 'class_num': 527,\n",
       " 'model_type': 'HTSAT',\n",
       " 'model_name': 'tiny'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_cfg['audio_cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio embeddings from audio data\n",
    "audio_data, _ = librosa.load('test_song.mp3', sr=48000) # sample rate should be 48000\n",
    "# audio_data = audio_data[:48000*15] # 5 seconds\n",
    "audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_dataset = EpidemicSoundDataset('/fastscratch/korte/es_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 ms ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03378514  0.08276038 -0.04029229 -0.03356505  0.02966368 -0.0266439\n",
      "   0.03970947 -0.00148861  0.03154013  0.02451845  0.03857341  0.02047969\n",
      "  -0.01352776 -0.02060715 -0.03384665  0.01845452  0.01468264  0.04995199\n",
      "  -0.02031711 -0.06094122]]\n",
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0131,  0.0785,  0.0767, -0.0259, -0.0184,  0.0028,  0.0451,  0.0133,\n",
      "         -0.0327,  0.0620, -0.0639,  0.0697,  0.0027, -0.0418, -0.0539,  0.0003,\n",
      "         -0.0098, -0.0034, -0.0337, -0.0032]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "# Get audio embeddings from audio data\n",
    "audio_data, _ = librosa.load('test_song.mp3', sr=48000) # sample rate should be 48000\n",
    "audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
    "audio_data = torch.from_numpy(int16_to_float32(float32_to_int16(audio_data))).float() # quantize before send it in to the model\n",
    "audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=True)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/korte/micromamba/envs/ml/lib/python3.9/site-packages/torchaudio/transforms/_transforms.py:611: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
      "  warnings.warn(\n",
      "/home/korte/micromamba/envs/ml/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 ms ± 16.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "audio_data = es_dataset[0]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = model.model.get_audio_embedding([audio_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5037e-02,  2.0186e-03, -5.7755e-02,  6.9711e-02,  1.5338e-02,\n",
       "          1.1432e-02,  4.1709e-02, -7.5621e-03, -9.7550e-02, -2.3002e-02,\n",
       "          1.7306e-02,  8.4966e-02,  2.1912e-03, -5.5164e-02, -1.5723e-02,\n",
       "         -2.5623e-02, -1.6994e-02, -4.3617e-02, -6.5937e-02,  2.6272e-03,\n",
       "          1.2739e-02,  6.1586e-03,  3.8209e-02, -8.8046e-02,  1.1829e-02,\n",
       "          1.7457e-02,  1.0160e-02,  2.0708e-02, -2.6445e-02, -1.3777e-02,\n",
       "          1.2003e-03,  9.4762e-02, -4.7691e-02,  3.7207e-02, -5.9242e-02,\n",
       "          5.9576e-03, -5.5460e-02, -2.3160e-02,  3.3704e-02, -4.3540e-03,\n",
       "          5.5291e-03, -1.5345e-02, -3.5983e-02, -1.0820e-02, -1.5250e-02,\n",
       "          2.8379e-02,  8.6993e-02,  4.7084e-02, -1.1649e-02,  3.4456e-02,\n",
       "          5.9233e-02,  1.5146e-02, -3.0219e-02,  4.1252e-02, -1.7663e-02,\n",
       "          5.4934e-03, -1.9642e-02,  3.9494e-03, -1.5750e-02, -1.5834e-02,\n",
       "         -1.8333e-02,  1.2006e-02, -3.1919e-02, -2.3923e-02,  5.1555e-02,\n",
       "          5.9433e-02,  8.4424e-02,  2.2191e-02, -7.2173e-02,  6.4645e-02,\n",
       "         -2.6177e-02, -7.7825e-02,  3.3720e-02, -1.6811e-02,  9.9388e-03,\n",
       "          8.4746e-02, -5.3273e-02,  2.3994e-02,  2.4952e-02,  1.5508e-02,\n",
       "         -6.6082e-02,  2.0277e-03, -6.5305e-02,  3.7895e-02, -3.7630e-02,\n",
       "          6.3610e-03, -2.6554e-02, -1.0740e-02, -3.1220e-03,  5.0496e-02,\n",
       "         -4.2835e-02,  3.3646e-03, -7.7521e-02, -4.1807e-02,  3.0624e-02,\n",
       "          5.7458e-02,  3.7979e-03, -4.6190e-03,  4.3507e-02,  1.0205e-01,\n",
       "         -2.4388e-02, -3.4861e-02, -7.6060e-02,  3.7280e-02,  2.8735e-02,\n",
       "         -2.0620e-03, -9.5465e-03,  2.2566e-02, -3.6298e-02,  8.1768e-03,\n",
       "         -1.1763e-02, -8.2391e-02,  4.8270e-02,  2.8222e-02,  1.8839e-02,\n",
       "         -2.5555e-02, -2.4553e-03, -2.4948e-03, -5.4544e-02,  3.5031e-02,\n",
       "         -1.7893e-02, -2.1491e-02, -2.0269e-02, -8.7880e-03,  2.9790e-02,\n",
       "         -2.0687e-02, -3.4167e-02,  6.9976e-02,  1.1593e-02, -1.7820e-02,\n",
       "          2.6297e-02,  4.0981e-02, -7.1115e-02, -1.6531e-02, -7.8659e-02,\n",
       "         -7.7760e-02, -1.2124e-02, -5.5683e-02,  4.2539e-02,  6.4511e-02,\n",
       "          2.5977e-02, -1.8260e-03, -9.7215e-02,  2.1389e-02, -5.1659e-02,\n",
       "         -4.0834e-02, -5.1177e-02,  1.7124e-02,  7.3875e-02, -1.8392e-02,\n",
       "          7.5969e-02, -5.9696e-02, -2.7356e-02,  4.4266e-03,  3.2856e-02,\n",
       "          2.9168e-02,  6.8218e-02,  2.9307e-02, -1.4111e-02, -3.3928e-02,\n",
       "         -7.5474e-02,  6.5373e-02, -2.0699e-02,  9.7415e-03, -2.0122e-02,\n",
       "         -1.3487e-01, -6.3034e-02, -2.4767e-02,  4.8179e-02,  3.5407e-02,\n",
       "         -8.6141e-02, -1.3804e-02,  2.5199e-02,  5.1043e-02, -9.5898e-03,\n",
       "          2.1842e-02, -9.9729e-02,  3.2922e-02, -2.0484e-02,  9.4455e-03,\n",
       "         -5.8175e-02, -3.4248e-02, -1.9296e-02,  1.3159e-02, -8.7722e-03,\n",
       "          6.7625e-02,  4.2941e-02,  2.8527e-02, -3.2349e-02,  3.2271e-03,\n",
       "         -2.1186e-02,  6.0866e-02,  1.6760e-03,  4.6289e-02, -4.6899e-02,\n",
       "          1.7587e-02,  2.5527e-02, -5.5514e-02, -8.6063e-02, -2.7193e-02,\n",
       "         -4.5842e-02, -3.4278e-02,  7.7234e-02, -7.1687e-02, -1.3774e-02,\n",
       "         -4.1902e-02,  3.9782e-02, -4.4371e-02,  1.7440e-02, -3.6783e-02,\n",
       "         -3.1587e-02, -1.3315e-03, -7.1286e-03,  2.2769e-02, -7.8176e-03,\n",
       "         -2.0706e-03, -9.4262e-02, -6.9361e-03,  2.1138e-02, -1.8344e-01,\n",
       "          1.7824e-02,  2.0713e-02, -3.7072e-02,  7.8480e-02,  2.0211e-03,\n",
       "          1.7030e-03,  5.2280e-02,  2.9687e-02, -1.4070e-02, -1.7031e-02,\n",
       "         -8.6321e-03, -8.4300e-02, -2.4345e-02, -2.5380e-03, -1.0322e-02,\n",
       "         -1.8870e-02,  1.2524e-01,  2.0088e-02,  9.4696e-02, -7.2545e-02,\n",
       "          5.4059e-03, -2.3125e-02,  6.5918e-02,  2.7997e-04, -5.4199e-03,\n",
       "         -1.3073e-02, -3.3463e-02,  7.7848e-02,  3.9513e-03, -6.4358e-03,\n",
       "         -6.6779e-03,  1.2820e-02, -4.0382e-02, -1.7437e-02,  1.4912e-02,\n",
       "         -3.8612e-02, -2.9847e-02,  5.4813e-02, -9.8918e-02, -1.2942e-02,\n",
       "          4.8019e-02, -4.9454e-02,  3.5848e-02, -5.6157e-02, -1.7156e-02,\n",
       "          1.5950e-02, -1.9373e-02,  1.6442e-02,  5.7849e-02, -2.6890e-02,\n",
       "          2.2976e-02, -1.0559e-02,  1.0681e-02,  4.6114e-02, -1.8236e-02,\n",
       "          1.0801e-02,  4.5221e-02, -2.5730e-02, -4.8730e-02, -5.0884e-02,\n",
       "         -1.2382e-01, -4.2577e-02,  3.0835e-02, -2.2849e-03, -1.3149e-02,\n",
       "          7.1735e-02, -7.4843e-02,  8.6508e-03,  1.8557e-02, -1.3649e-02,\n",
       "          6.9424e-03, -1.7093e-02,  3.5281e-02,  5.2317e-02, -1.5776e-02,\n",
       "         -1.0157e-01,  3.1310e-02,  3.2678e-02, -4.7466e-02,  3.0589e-02,\n",
       "          2.6843e-02, -2.2409e-02,  5.1775e-02, -8.0611e-02,  2.9422e-02,\n",
       "         -9.4160e-04, -5.1089e-02, -1.2798e-01, -1.7615e-03,  2.4732e-02,\n",
       "         -3.2160e-03,  1.5923e-02, -1.3208e-02,  1.5254e-02,  2.3324e-02,\n",
       "          4.2591e-02,  7.4196e-03,  3.9483e-02,  2.8579e-02,  2.6200e-02,\n",
       "         -4.6071e-02, -4.7067e-02, -2.9655e-02, -8.0087e-03, -4.3336e-02,\n",
       "          2.3490e-02,  3.0034e-04,  9.2088e-04,  1.6607e-02, -8.0988e-03,\n",
       "          4.5329e-02,  3.4579e-02, -3.2467e-02,  1.4156e-01, -2.3591e-02,\n",
       "         -3.3214e-02,  6.7811e-03, -1.4698e-02,  4.2148e-03,  3.7497e-02,\n",
       "         -5.6595e-02,  1.1682e-02, -8.2830e-03, -1.4202e-02, -1.1788e-01,\n",
       "         -3.0913e-02, -8.4764e-03, -5.3539e-02,  6.9415e-02, -4.4519e-03,\n",
       "          3.6531e-02,  1.3245e-02, -7.3427e-02, -8.9067e-03, -9.3298e-02,\n",
       "          5.6449e-02,  6.1838e-02,  3.4706e-02,  3.6139e-02,  1.4484e-02,\n",
       "          2.8021e-02,  3.5146e-02,  2.3450e-02,  6.8747e-02,  7.7378e-02,\n",
       "         -3.4704e-02, -5.0312e-02, -5.5889e-02, -4.2466e-02, -4.0803e-02,\n",
       "          1.2275e-02, -8.0812e-03, -4.3052e-02,  7.3777e-02,  5.2724e-02,\n",
       "         -1.8813e-02,  4.0053e-02, -3.6136e-02,  2.5251e-02,  4.9943e-02,\n",
       "         -2.5556e-02,  1.1566e-01,  2.2814e-02, -8.6133e-02,  7.0925e-02,\n",
       "          3.6057e-03, -2.3486e-02,  7.0167e-04,  3.6669e-02, -4.3977e-02,\n",
       "         -1.5018e-02, -9.5575e-03,  4.8811e-02, -5.6434e-02,  1.7692e-02,\n",
       "          3.7871e-02,  3.1762e-02, -3.0031e-02,  2.9096e-02,  4.7210e-02,\n",
       "          1.4474e-03,  8.9991e-02,  7.9625e-02,  4.0983e-02, -8.8595e-02,\n",
       "         -8.8688e-02, -3.0131e-02, -5.4563e-02,  1.4137e-02,  4.9203e-02,\n",
       "         -3.6260e-02,  6.7094e-02, -3.6649e-03,  7.4855e-02, -5.4477e-03,\n",
       "          1.6915e-02, -3.5346e-02, -1.0608e-03, -9.2905e-04, -1.9427e-02,\n",
       "         -2.7294e-03,  2.0579e-02, -3.5302e-02,  3.8164e-03,  1.9432e-02,\n",
       "          2.7660e-02, -7.6655e-03,  9.1986e-02,  5.2475e-02, -7.4606e-02,\n",
       "          5.4011e-02,  3.9145e-02, -4.0686e-02, -7.4376e-03,  3.7766e-02,\n",
       "          1.7538e-02,  3.4843e-02, -3.5402e-05, -3.0800e-02, -2.1510e-02,\n",
       "          5.1462e-02, -1.6478e-02, -4.1981e-02, -7.6769e-03, -5.8809e-03,\n",
       "         -2.3190e-02,  4.1163e-03, -8.0386e-03,  4.8524e-02,  2.8715e-03,\n",
       "          1.8089e-02, -1.2116e-02,  1.9141e-02,  5.3642e-03,  4.9334e-02,\n",
       "          9.9879e-02,  3.2272e-02, -5.3657e-02,  4.3250e-02,  3.7822e-02,\n",
       "          3.3596e-02, -2.0292e-02, -1.0986e-03,  2.3444e-02, -5.9026e-03,\n",
       "          8.5005e-02, -4.1071e-02,  8.9010e-03, -3.7968e-03, -8.3164e-02,\n",
       "          2.1345e-03, -3.4986e-02,  3.7677e-03, -5.4394e-02, -4.7314e-02,\n",
       "         -4.2606e-03, -5.0862e-04, -4.1162e-02,  2.7998e-02, -1.8164e-02,\n",
       "         -5.4896e-02, -2.9735e-02, -1.3411e-02,  6.8430e-03,  6.0666e-04,\n",
       "         -7.1080e-02,  3.3577e-02, -3.0006e-02,  8.4942e-03,  3.5615e-02,\n",
       "          3.9751e-02, -3.5028e-02,  4.5574e-02,  6.8687e-02, -7.2976e-02,\n",
       "         -4.7168e-02, -2.4610e-02, -5.8004e-02,  4.1612e-02,  2.9680e-02,\n",
       "          1.1754e-02,  1.7455e-02,  6.2984e-02, -5.3940e-03, -1.2974e-03,\n",
       "          4.1760e-03, -1.9674e-02, -2.7521e-02,  1.5860e-02,  1.1577e-02,\n",
       "         -9.1555e-03, -1.3112e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_embed.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
