# lightning.pytorch==2.0.6
seed_everything: true
trainer:
  accelerator: 'gpu'
  strategy: 'deepspeed_stage_2'
  devices: auto
  num_nodes: 1
  precision: 16
  log_every_n_steps: 10
  # val_check_interval: 0.5
  check_val_every_n_epoch: 5
  default_root_dir: '/scratch/korte/audiffuse'
  callbacks:
      class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: -1
        monitor: 'val/loss'
        mode: 'min'
        filename: 'diffuser-{epoch:03d}-{val/loss:.2f}'
        every_n_epochs: 5
        save_last: true
  gradient_clip_val: 1.0
  fast_dev_run: false
  max_epochs: 1000
model:
  diffuser_config: Null
  first_stage_ckpt: '/scratch/korte/audiffuse/sd14_ae_ckpt' #"/scratch/korte/audiffuse/autoencoder_ckpt"
  cond_stage_ckpt: 'm-a-p/MERT-v1-95M'
  freeze_cond_stage: true
  loss_func: mse
  noise_scheduler_timesteps: 1000
  use_lr_scheduler: false
  lr: 1e-4
  val_gen_freq: 1
data:
  data_dir: '/fastscratch/korte/es-dataset'
  batch_size: 4
  num_workers_train: 32
  num_workers_val: 4
  num_workers_val_gen: 2
  clip_samples: 0
  val_gen_images: 4
ckpt_path: 
